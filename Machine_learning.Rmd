---
title: "Predictive Modeling using Random Forests in the Caret Package"
author: "Mesfin Gebeyaw"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis

The raw data for this project was collected from a study of six young male health participants using accelerometers on the belt, forearm, arm and dumbells who were instructed to perform dumbell biceps curl in five different ways representing the correct form and four other ways of common mistakes.  

The objective of this project analysis was to demonstrate the applicablility of machine learning algorithms in model building to predict the manner in which the participants did the exercise. 

The predicitve model using random forest in the caret package suggested that 20 variables are the most informative predicators. A 99.1% predicative accuracy and a kappa of 98.9% has been achieved.

## Download datasets directly from the web site 
```{r }
trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(trainUrl, destfile= "./pm1_training.csv")

testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(testUrl, destfile= "./pm1_testing.csv")

dateDownloaded <- date()
dateDownloaded
```

## load datasets in R
```{r }
train.data <- read.csv("pm1_training.csv", header=TRUE)
test.data <- read.csv("pm1_testing.csv", header=TRUE)
str(train.data)
```

## Data Processing
```{r }
## estimate the extent of missing values in the datasets
mean(is.na(train.data))
```
Approximately 41% of the observations are missing. So, we need to remove those variables with missing values from the analysis

```{r}
### Create a lookup table for the variables with missing values and subset the raw datasets without these variables

cols_to_drop <- grep("^X|^var_|^stddev_|^avg|^kurtosis_|^skewness_|^min_*|^max_|^amplitude_*|*_timestamp*|*_window*|^user", names(train.data))

train.data <- train.data[-cols_to_drop]
test.data <- test.data[-cols_to_drop]
```
```{r}
## partition raw data into 70% testing and 30% testing data set
library(caret)
inTrain <- createDataPartition(train.data$classe, p=0.7, list=FALSE) 

set.seed(324)

training <- train.data[inTrain,]
testing <- train.data[-inTrain,]
rm(train.data)
```

```{r}
dim(training)
```

```{r}
dim(testing)
```

## Training decision tree with random forest

```{r}
modFit <- train(classe ~ ., method="rf", data=training)
print(modFit)
modFit$finalModel
```

## Variable Importance: which variales are most informative predictors
```{r}
varImp(modFit)
```

## Evaluate the predictive model on the testing dataset

```{r}
prediction <- predict(modFit, newdata=testing)
tab <- table(prediction, testing$classe)
tab
```
```{r}
sum(diag(tab))/sum(tab)
```

```{r}
confusionMatrix(prediction, testing$classe)
```

a predictive model with a 99.4% accuracy and a kappa of 99.2% are far greater than the 28.5% No information rate.  This is nice!